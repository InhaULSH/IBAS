{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"f8d3a971f0304fa1a63d74da48acef74":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a325f77a50ba414e878c5cb1bcc38dc0","IPY_MODEL_c4ae49645638432e90eadb8e37448d4a","IPY_MODEL_f89cfd8da98946d58920778f00cbcf65"],"layout":"IPY_MODEL_7e428a98facb4eaeaab1522f59a613e5"}},"a325f77a50ba414e878c5cb1bcc38dc0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_72023f3bc5784935a6cd66935b85652c","placeholder":"​","style":"IPY_MODEL_e1eaed069f154ffe8bb24abbc0954c88","value":"Batches: 100%"}},"c4ae49645638432e90eadb8e37448d4a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a85024c98c44a95b0036d12bb09194a","max":219,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e5f14c20ae5949188ecdf84381de9adc","value":219}},"f89cfd8da98946d58920778f00cbcf65":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d8cd62a0a8c4cde95dae63ecdd9e86e","placeholder":"​","style":"IPY_MODEL_ec48be5421624816b59ffa26f0385ab5","value":" 219/219 [00:43&lt;00:00, 23.57it/s]"}},"7e428a98facb4eaeaab1522f59a613e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"72023f3bc5784935a6cd66935b85652c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1eaed069f154ffe8bb24abbc0954c88":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8a85024c98c44a95b0036d12bb09194a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5f14c20ae5949188ecdf84381de9adc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4d8cd62a0a8c4cde95dae63ecdd9e86e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec48be5421624816b59ffa26f0385ab5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"XbVbVL2OlEH_","colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"status":"ok","timestamp":1763554964091,"user_tz":-540,"elapsed":145528,"user":{"displayName":"이상호","userId":"07129413416403769389"}},"outputId":"73bb1f77-5da1-4f9e-a12c-7751e29a898a"},"outputs":[{"output_type":"stream","name":"stdout","text":["\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n","\r0% [Waiting for headers] [Waiting for headers] [1 InRelease 3,632 B/3,632 B 100\r                                                                               \rGet:2 https://cli.github.com/packages stable InRelease [3,917 B]\n","Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n","Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n","Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n","Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n","Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,149 kB]\n","Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Get:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n","Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,829 kB]\n","Get:14 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,532 kB]\n","Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,465 kB]\n","Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,595 kB]\n","Get:17 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [5,988 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,864 kB]\n","Get:19 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,290 kB]\n","Fetched 31.1 MB in 7s (4,196 kB/s)\n","Reading package lists... Done\n","W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","g++ is already the newest version (4:11.2.0-1ubuntu1).\n","g++ set to manually installed.\n","The following additional packages will be installed:\n","  at-spi2-core fonts-dejavu-core fonts-dejavu-extra gsettings-desktop-schemas\n","  javascript-common libatk-bridge2.0-0 libatk-wrapper-java\n","  libatk-wrapper-java-jni libatk1.0-0 libatk1.0-data libatspi2.0-0\n","  libgail-common libgail18 libgtk2.0-0 libgtk2.0-bin libgtk2.0-common\n","  libjs-sphinxdoc libjs-underscore librsvg2-common libxcomposite1 libxt-dev\n","  libxtst6 libxxf86dga1 openjdk-8-jdk-headless openjdk-8-jre\n","  openjdk-8-jre-headless python3.10-dev session-migration x11-utils\n","Suggested packages:\n","  apache2 | lighttpd | httpd gvfs libxt-doc openjdk-8-demo openjdk-8-source\n","  visualvm libnss-mdns fonts-nanum fonts-ipafont-gothic fonts-ipafont-mincho\n","  fonts-wqy-microhei fonts-wqy-zenhei fonts-indic mesa-utils\n","The following NEW packages will be installed:\n","  at-spi2-core fonts-dejavu-core fonts-dejavu-extra gsettings-desktop-schemas\n","  javascript-common libatk-bridge2.0-0 libatk-wrapper-java\n","  libatk-wrapper-java-jni libatk1.0-0 libatk1.0-data libatspi2.0-0\n","  libgail-common libgail18 libgtk2.0-0 libgtk2.0-bin libgtk2.0-common\n","  libjs-sphinxdoc libjs-underscore librsvg2-common libxcomposite1 libxt-dev\n","  libxtst6 libxxf86dga1 openjdk-8-jdk openjdk-8-jdk-headless openjdk-8-jre\n","  openjdk-8-jre-headless python3-dev python3.10-dev session-migration\n","  x11-utils\n","0 upgraded, 31 newly installed, 0 to remove and 41 not upgraded.\n","Need to get 51.1 MB of archives.\n","After this operation, 171 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatspi2.0-0 amd64 2.44.0-3 [80.9 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 session-migration amd64 0.3.6 [9,774 B]\n","Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 gsettings-desktop-schemas all 42.0-1ubuntu1 [31.1 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 at-spi2-core amd64 2.44.0-3 [54.4 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-core all 2.37-2build1 [1,041 kB]\n","Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-extra all 2.37-2build1 [2,041 kB]\n","Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 javascript-common all 11+nmu1 [5,936 B]\n","Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk1.0-data all 2.36.0-3build1 [2,824 B]\n","Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk1.0-0 amd64 2.36.0-3build1 [51.9 kB]\n","Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-bridge2.0-0 amd64 2.38.0-3 [66.6 kB]\n","Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcomposite1 amd64 1:0.4.5-1build2 [7,192 B]\n","Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxxf86dga1 amd64 2:1.1.5-0ubuntu3 [12.6 kB]\n","Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-utils amd64 7.7+5build2 [206 kB]\n","Get:15 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java all 0.38.0-5build1 [53.1 kB]\n","Get:16 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java-jni amd64 0.38.0-5build1 [49.0 kB]\n","Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-common all 2.24.33-2ubuntu2.1 [125 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-0 amd64 2.24.33-2ubuntu2.1 [2,038 kB]\n","Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgail18 amd64 2.24.33-2ubuntu2.1 [15.9 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgail-common amd64 2.24.33-2ubuntu2.1 [132 kB]\n","Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-bin amd64 2.24.33-2ubuntu2.1 [7,936 B]\n","Get:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-underscore all 1.13.2~dfsg-2 [118 kB]\n","Get:23 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-sphinxdoc all 4.3.2-1 [139 kB]\n","Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 librsvg2-common amd64 2.52.5+dfsg-3ubuntu0.2 [17.7 kB]\n","Get:25 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxt-dev amd64 1:1.2.1-1 [396 kB]\n","Get:26 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-8-jre-headless amd64 8u462-ga~us1-0ubuntu2~22.04.2 [30.8 MB]\n","Get:27 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-8-jre amd64 8u462-ga~us1-0ubuntu2~22.04.2 [75.5 kB]\n","Get:28 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-8-jdk-headless amd64 8u462-ga~us1-0ubuntu2~22.04.2 [8,849 kB]\n","Get:29 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-8-jdk amd64 8u462-ga~us1-0ubuntu2~22.04.2 [4,105 kB]\n","Get:30 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10-dev amd64 3.10.12-1~22.04.11 [508 kB]\n","Get:31 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-dev amd64 3.10.6-1~22.04.1 [26.0 kB]\n","Fetched 51.1 MB in 2s (25.7 MB/s)\n","Extracting templates from packages: 100%\n","Selecting previously unselected package libatspi2.0-0:amd64.\n","(Reading database ... 121713 files and directories currently installed.)\n","Preparing to unpack .../00-libatspi2.0-0_2.44.0-3_amd64.deb ...\n","Unpacking libatspi2.0-0:amd64 (2.44.0-3) ...\n","Selecting previously unselected package libxtst6:amd64.\n","Preparing to unpack .../01-libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n","Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n","Selecting previously unselected package session-migration.\n","Preparing to unpack .../02-session-migration_0.3.6_amd64.deb ...\n","Unpacking session-migration (0.3.6) ...\n","Selecting previously unselected package gsettings-desktop-schemas.\n","Preparing to unpack .../03-gsettings-desktop-schemas_42.0-1ubuntu1_all.deb ...\n","Unpacking gsettings-desktop-schemas (42.0-1ubuntu1) ...\n","Selecting previously unselected package at-spi2-core.\n","Preparing to unpack .../04-at-spi2-core_2.44.0-3_amd64.deb ...\n","Unpacking at-spi2-core (2.44.0-3) ...\n","Selecting previously unselected package fonts-dejavu-core.\n","Preparing to unpack .../05-fonts-dejavu-core_2.37-2build1_all.deb ...\n","Unpacking fonts-dejavu-core (2.37-2build1) ...\n","Selecting previously unselected package fonts-dejavu-extra.\n","Preparing to unpack .../06-fonts-dejavu-extra_2.37-2build1_all.deb ...\n","Unpacking fonts-dejavu-extra (2.37-2build1) ...\n","Selecting previously unselected package javascript-common.\n","Preparing to unpack .../07-javascript-common_11+nmu1_all.deb ...\n","Unpacking javascript-common (11+nmu1) ...\n","Selecting previously unselected package libatk1.0-data.\n","Preparing to unpack .../08-libatk1.0-data_2.36.0-3build1_all.deb ...\n","Unpacking libatk1.0-data (2.36.0-3build1) ...\n","Selecting previously unselected package libatk1.0-0:amd64.\n","Preparing to unpack .../09-libatk1.0-0_2.36.0-3build1_amd64.deb ...\n","Unpacking libatk1.0-0:amd64 (2.36.0-3build1) ...\n","Selecting previously unselected package libatk-bridge2.0-0:amd64.\n","Preparing to unpack .../10-libatk-bridge2.0-0_2.38.0-3_amd64.deb ...\n","Unpacking libatk-bridge2.0-0:amd64 (2.38.0-3) ...\n","Selecting previously unselected package libxcomposite1:amd64.\n","Preparing to unpack .../11-libxcomposite1_1%3a0.4.5-1build2_amd64.deb ...\n","Unpacking libxcomposite1:amd64 (1:0.4.5-1build2) ...\n","Selecting previously unselected package libxxf86dga1:amd64.\n","Preparing to unpack .../12-libxxf86dga1_2%3a1.1.5-0ubuntu3_amd64.deb ...\n","Unpacking libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n","Selecting previously unselected package x11-utils.\n","Preparing to unpack .../13-x11-utils_7.7+5build2_amd64.deb ...\n","Unpacking x11-utils (7.7+5build2) ...\n","Selecting previously unselected package libatk-wrapper-java.\n","Preparing to unpack .../14-libatk-wrapper-java_0.38.0-5build1_all.deb ...\n","Unpacking libatk-wrapper-java (0.38.0-5build1) ...\n","Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n","Preparing to unpack .../15-libatk-wrapper-java-jni_0.38.0-5build1_amd64.deb ...\n","Unpacking libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n","Selecting previously unselected package libgtk2.0-common.\n","Preparing to unpack .../16-libgtk2.0-common_2.24.33-2ubuntu2.1_all.deb ...\n","Unpacking libgtk2.0-common (2.24.33-2ubuntu2.1) ...\n","Selecting previously unselected package libgtk2.0-0:amd64.\n","Preparing to unpack .../17-libgtk2.0-0_2.24.33-2ubuntu2.1_amd64.deb ...\n","Unpacking libgtk2.0-0:amd64 (2.24.33-2ubuntu2.1) ...\n","Selecting previously unselected package libgail18:amd64.\n","Preparing to unpack .../18-libgail18_2.24.33-2ubuntu2.1_amd64.deb ...\n","Unpacking libgail18:amd64 (2.24.33-2ubuntu2.1) ...\n","Selecting previously unselected package libgail-common:amd64.\n","Preparing to unpack .../19-libgail-common_2.24.33-2ubuntu2.1_amd64.deb ...\n","Unpacking libgail-common:amd64 (2.24.33-2ubuntu2.1) ...\n","Selecting previously unselected package libgtk2.0-bin.\n","Preparing to unpack .../20-libgtk2.0-bin_2.24.33-2ubuntu2.1_amd64.deb ...\n","Unpacking libgtk2.0-bin (2.24.33-2ubuntu2.1) ...\n","Selecting previously unselected package libjs-underscore.\n","Preparing to unpack .../21-libjs-underscore_1.13.2~dfsg-2_all.deb ...\n","Unpacking libjs-underscore (1.13.2~dfsg-2) ...\n","Selecting previously unselected package libjs-sphinxdoc.\n","Preparing to unpack .../22-libjs-sphinxdoc_4.3.2-1_all.deb ...\n","Unpacking libjs-sphinxdoc (4.3.2-1) ...\n","Selecting previously unselected package librsvg2-common:amd64.\n","Preparing to unpack .../23-librsvg2-common_2.52.5+dfsg-3ubuntu0.2_amd64.deb ...\n","Unpacking librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n","Selecting previously unselected package libxt-dev:amd64.\n","Preparing to unpack .../24-libxt-dev_1%3a1.2.1-1_amd64.deb ...\n","Unpacking libxt-dev:amd64 (1:1.2.1-1) ...\n","Selecting previously unselected package openjdk-8-jre-headless:amd64.\n","Preparing to unpack .../25-openjdk-8-jre-headless_8u462-ga~us1-0ubuntu2~22.04.2_amd64.deb ...\n","Unpacking openjdk-8-jre-headless:amd64 (8u462-ga~us1-0ubuntu2~22.04.2) ...\n","Selecting previously unselected package openjdk-8-jre:amd64.\n","Preparing to unpack .../26-openjdk-8-jre_8u462-ga~us1-0ubuntu2~22.04.2_amd64.deb ...\n","Unpacking openjdk-8-jre:amd64 (8u462-ga~us1-0ubuntu2~22.04.2) ...\n","Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n","Preparing to unpack .../27-openjdk-8-jdk-headless_8u462-ga~us1-0ubuntu2~22.04.2_amd64.deb ...\n","Unpacking openjdk-8-jdk-headless:amd64 (8u462-ga~us1-0ubuntu2~22.04.2) ...\n","Selecting previously unselected package openjdk-8-jdk:amd64.\n","Preparing to unpack .../28-openjdk-8-jdk_8u462-ga~us1-0ubuntu2~22.04.2_amd64.deb ...\n","Unpacking openjdk-8-jdk:amd64 (8u462-ga~us1-0ubuntu2~22.04.2) ...\n","Selecting previously unselected package python3.10-dev.\n","Preparing to unpack .../29-python3.10-dev_3.10.12-1~22.04.11_amd64.deb ...\n","Unpacking python3.10-dev (3.10.12-1~22.04.11) ...\n","Selecting previously unselected package python3-dev.\n","Preparing to unpack .../30-python3-dev_3.10.6-1~22.04.1_amd64.deb ...\n","Unpacking python3-dev (3.10.6-1~22.04.1) ...\n","Setting up javascript-common (11+nmu1) ...\n","Setting up session-migration (0.3.6) ...\n","Created symlink /etc/systemd/user/graphical-session-pre.target.wants/session-migration.service → /usr/lib/systemd/user/session-migration.service.\n","Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n","Setting up libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n","Setting up libatspi2.0-0:amd64 (2.44.0-3) ...\n","Setting up libxt-dev:amd64 (1:1.2.1-1) ...\n","Setting up openjdk-8-jre-headless:amd64 (8u462-ga~us1-0ubuntu2~22.04.2) ...\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/jjs to provide /usr/bin/jjs (jjs) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/pack200 to provide /usr/bin/pack200 (pack200) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/rmid to provide /usr/bin/rmid (rmid) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/unpack200 to provide /usr/bin/unpack200 (unpack200) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n","Setting up fonts-dejavu-core (2.37-2build1) ...\n","Setting up librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n","Setting up libatk1.0-data (2.36.0-3build1) ...\n","Setting up fonts-dejavu-extra (2.37-2build1) ...\n","Setting up python3.10-dev (3.10.12-1~22.04.11) ...\n","Setting up libgtk2.0-common (2.24.33-2ubuntu2.1) ...\n","Setting up libatk1.0-0:amd64 (2.36.0-3build1) ...\n","Setting up libxcomposite1:amd64 (1:0.4.5-1build2) ...\n","Setting up libjs-underscore (1.13.2~dfsg-2) ...\n","Setting up gsettings-desktop-schemas (42.0-1ubuntu1) ...\n","Setting up libgtk2.0-0:amd64 (2.24.33-2ubuntu2.1) ...\n","Setting up libatk-bridge2.0-0:amd64 (2.38.0-3) ...\n","Setting up openjdk-8-jdk-headless:amd64 (8u462-ga~us1-0ubuntu2~22.04.2) ...\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/rmic to provide /usr/bin/rmic (rmic) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n","Setting up libjs-sphinxdoc (4.3.2-1) ...\n","Setting up libgail18:amd64 (2.24.33-2ubuntu2.1) ...\n","Setting up libgtk2.0-bin (2.24.33-2ubuntu2.1) ...\n","Setting up x11-utils (7.7+5build2) ...\n","Setting up libatk-wrapper-java (0.38.0-5build1) ...\n","Setting up libgail-common:amd64 (2.24.33-2ubuntu2.1) ...\n","Setting up libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n","Setting up python3-dev (3.10.6-1~22.04.1) ...\n","Setting up openjdk-8-jre:amd64 (8u462-ga~us1-0ubuntu2~22.04.2) ...\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/policytool to provide /usr/bin/policytool (policytool) in auto mode\n","Setting up openjdk-8-jdk:amd64 (8u462-ga~us1-0ubuntu2~22.04.2) ...\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/appletviewer to provide /usr/bin/appletviewer (appletviewer) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\n","Processing triggers for libgdk-pixbuf-2.0-0:amd64 (2.42.8+dfsg-1ubuntu0.4) ...\n","Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n","Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n","Processing triggers for hicolor-icon-theme (0.17-2) ...\n","Processing triggers for libglib2.0-0:amd64 (2.72.4-0ubuntu2.6) ...\n","Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n","/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n","\n","Processing triggers for man-db (2.10.2-1) ...\n","Setting up at-spi2-core (2.44.0-3) ...\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n","Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.1.1)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n","Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.2)\n","Collecting bertopic\n","  Downloading bertopic-0.17.3-py3-none-any.whl.metadata (24 kB)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (1.5.2)\n","Collecting umap\n","  Downloading umap-0.1.1.tar.gz (3.2 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.27.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n","Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n","Requirement already satisfied: hdbscan>=0.8.29 in /usr/local/lib/python3.12/dist-packages (from bertopic) (0.8.40)\n","Requirement already satisfied: umap-learn>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from bertopic) (0.5.9.post2)\n","Requirement already satisfied: plotly>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from bertopic) (5.24.1)\n","Requirement already satisfied: llvmlite>0.36.0 in /usr/local/lib/python3.12/dist-packages (from bertopic) (0.43.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly>=4.7.0->bertopic) (8.5.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n","Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.12/dist-packages (from umap-learn>=0.5.0->bertopic) (0.60.0)\n","Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.12/dist-packages (from umap-learn>=0.5.0->bertopic) (0.5.13)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n","Downloading bertopic-0.17.3-py3-none-any.whl (153 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: umap\n","  Building wheel for umap (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for umap: filename=umap-0.1.1-py3-none-any.whl size=3541 sha256=3070e376a86b29de9d3521cb0292b17e7afa8a25e72982ec42051c2bf17ae02b\n","  Stored in directory: /root/.cache/pip/wheels/48/4a/1c/1d511cbb0413a448d8546e958f8e82b98d9bb493038d19ece2\n","Successfully built umap\n","Installing collected packages: umap, bertopic\n","Successfully installed bertopic-0.17.3 umap-0.1.1\n","Mounted at /content/drive\n"]}],"source":["!apt-get update\n","!apt-get install -y g++ openjdk-8-jdk python3-dev   # 필요시\n","!pip install pandas scikit-learn xgboost transformers sentence-transformers bertopic joblib umap\n","\n","# 코랩에서:\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!apt-get update\n","!pip install \"jpype1==1.5.0\" konlpy\n","import os\n","\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"PATH\"] += os.pathsep + os.path.join(os.environ[\"JAVA_HOME\"], \"bin\")\n","\n","from konlpy.tag import Komoran\n","\n","komoran = Komoran()\n","print(komoran.morphs(\"JPype와 Komoran 테스트 중입니다.\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"D9IiYzB6ntyr","executionInfo":{"status":"ok","timestamp":1763392536696,"user_tz":-540,"elapsed":13615,"user":{"displayName":"이상호/학생/경영학","userId":"05009782283079843159"}},"outputId":"7d6319e1-f2c6-43bd-908e-d6f3960c12b4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\r0% [Working]\r            \rHit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n","\r0% [Connecting to archive.ubuntu.com (91.189.91.81)] [Connecting to security.ub\r                                                                               \rHit:2 https://cli.github.com/packages stable InRelease\n","\r0% [Connecting to archive.ubuntu.com (91.189.91.81)] [Connecting to security.ub\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Connectin\r                                                                               \rHit:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n","\r0% [Waiting for headers] [Waiting for headers] [Connecting to r2u.stat.illinois\r                                                                               \rHit:4 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","\r0% [Waiting for headers] [Waiting for headers] [Connecting to r2u.stat.illinois\r                                                                               \rHit:5 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","\r0% [Waiting for headers] [Waiting for headers] [Connecting to r2u.stat.illinois\r                                                                               \rHit:6 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","\r0% [Waiting for headers] [Waiting for headers] [Connecting to r2u.stat.illinois\r0% [Waiting for headers] [Waiting for headers] [Connecting to r2u.stat.illinois\r                                                                               \rHit:7 http://security.ubuntu.com/ubuntu jammy-security InRelease\n","Hit:8 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Hit:9 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n","Hit:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n","Hit:11 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n","Reading package lists... Done\n","W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n","Requirement already satisfied: jpype1==1.5.0 in /usr/local/lib/python3.12/dist-packages (1.5.0)\n","Requirement already satisfied: konlpy in /usr/local/lib/python3.12/dist-packages (0.6.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from jpype1==1.5.0) (25.0)\n","Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from konlpy) (5.4.0)\n","Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.12/dist-packages (from konlpy) (2.0.2)\n","['JPype', '와', 'Komoran', '테스트', '중', '이', 'ㅂ니다', '.']\n"]}]},{"cell_type":"code","source":["# %% 전역상수 선언\n","import re\n","import pathlib\n","import torch\n","from konlpy.tag import Komoran\n","from sentence_transformers import SentenceTransformer\n","\n","PROJECT_ROOT = pathlib.Path('/content/drive/MyDrive/IBAS')\n","DATA_ROOT = PROJECT_ROOT / 'DataSet_DATAUP2025'\n","RAW_DIR = DATA_ROOT / 'RawData'\n","CLEANED_DIR = DATA_ROOT / 'Cleaned'\n","MODELS_DIR = DATA_ROOT / 'Models'\n","SCORED_DIR = DATA_ROOT / 'Scored'\n","LABELED_DIR = DATA_ROOT / 'StrongLabeled'\n","\n","MIN_REVIEW_LENGTH = 10\n","KAKAO_TO_NAVER_COLS = {\n","    \"가게이름\": \"가게이름\",          # 동일 의미\n","    \"카테고리\": \"카테고리\",          # 동일 의미\n","    \"전체평점\": \"전체평점\",          # 동일 의미\n","    \"평점건수\": \"방문자리뷰\",        # Kakao 평점건수 → Naver 방문자리뷰(리뷰 수)\n","    \"리뷰작성자\": \"리뷰작성자\",      # 동일 의미\n","    \"작성자리뷰작성수\": \"리뷰작성수\",  # Kakao 작성자리뷰작성수 → Naver 리뷰작성수\n","    \"리뷰내용\": \"리뷰내용\",          # 동일 의미\n","    \"리뷰작성일\": \"방문시간\",        # Kakao 리뷰작성일 → Naver 방문시간(시점)\n","    # Kakao의 '작성자평균평점', '리뷰평점' 등은 Naver에 대응 컬럼이 없으므로 매핑하지 않음\n","}\n","\n","\n","ALLOWED_PATTERN = re.compile(r'[^가-힣ㄱ-ㅎㅏ-ㅣA-Za-z0-9\\\\s.,?!]+') # 형태소 분석 모델에서 처리하지 못 하는 문자열\n","PUNCT_SKIP_PATTERN = re.compile(r\"^[^\\w가-힣]+$\")\n","MORPH_ANALYZER = Komoran()\n","KEYWORD_POS_TAGS = {\"NNG\", \"NNP\", \"VA\", \"MAG\", \"XR\"}\n","SBERT_MODEL = SentenceTransformer('jhgan/ko-sbert-sts',\n","            device = 'cuda' if torch.cuda.is_available() else 'cpu') # SBERT 모델"],"metadata":{"collapsed":true,"id":"dCwor0cFb5KY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763392602546,"user_tz":-540,"elapsed":35637,"user":{"displayName":"이상호/학생/경영학","userId":"05009782283079843159"}},"outputId":"01b37698-5cdb-4b77-ffcf-8e26d03d3c7a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["# %% 전용 소규모 한국어 사전\n","MENU_TERMS = {\n","    # 고기/한식 메인\n","    \"고기\", \"삼겹살\", \"목살\", \"갈비\", \"갈비탕\", \"돼지\", \"돼지고기\",\n","    \"소고기\", \"소금구이\", \"갈매기살\", \"족발\", \"보쌈\", \"등심\", \"대패\",\n","    \"오리\", \"통닭\", \"닭갈비\", \"닭발\", \"닭볶음탕\", \"대창\", \"곱창\",\n","    \"돼지갈비\", \"육회\", \"육전\", \"불고기\", \"육개장\",\n","\n","    # 탕/찌개/국/국밥\n","    \"국물\", \"감자탕\", \"된장찌개\", \"김치찌개\", \"해장국\", \"전골\", \"곱창전골\",\n","    \"곰탕\", \"설렁탕\", \"순두부찌개\", \"순두부\", \"무침\", \"탕수육\", \"감자전\",\n","    \"해물\", \"해산물\", \"게장\", \"꽃게\", \"해물탕\",\n","\n","    # 면/분식류\n","    \"떡볶이\", \"쫄면\", \"우동\", \"라멘\", \"라면\", \"국수\", \"칼국수\",\n","    \"냉면\", \"막국수\", \"쌀국수\", \"짬뽕\", \"짜장면\", \"비빔국수\",\n","    \"순대\", \"순대국\", \"김밥\", \"만두\", \"오뎅\", \"어묵\", \"분식\", \"분식집\",\n","\n","    # 일식/양식/기타\n","    \"초밥\", \"사시미\", \"소바\", \"덮밥\", \"돈가스\", \"파스타\", \"스파게티\",\n","    \"스테이크\", \"피자\", \"버거\", \"햄버거\", \"토스트\", \"샌드위치\",\n","    \"브런치\", \"와인\", \"카레\", \"팟타이\", \"보리밥\",\n","\n","    # 사이드/디저트\n","    \"반찬\", \"밑반찬\", \"샐러드\", \"계란찜\", \"계란말이\", \"아이스크림\",\n","    \"디저트\", \"와플\", \"빙수\", \"팥빙수\", \"과일\", \"케이크\",\n","    \"치즈볼\", \"에이드\", \"커피\", \"아메리카노\", \"음료\", \"주스\",\n","\n","    # 재료/토핑\n","    \"김치\", \"새우\", \"연어\", \"버섯\", \"마늘\", \"숙주\", \"명란\", \"야채\",\n","    \"채소\", \"베이컨\", \"고구마\", \"계란\", \"콩나물\", \"양파\", \"미나리\",\n","}\n","\n","TASTE_TERMS = {\n","    \"맛있\", \"맛나\", \"맛없\", \"고소\", \"달달\", \"달콤\", \"짭짤\",\n","    \"맵\", \"매콤\", \"얼큰\", \"담백\", \"진한\", \"싱겁\", \"느끼\",\n","    \"깔끔\", \"부드럽\", \"쫄깃\", \"바삭\", \"바삭바삭\", \"촉촉\",\n","    \"싱싱\", \"신선\", \"풍부\", \"풍미\", \"담백\", \"진리\", \"꿀맛\",\n","}\n","\n","SERVICE_TERMS = {\n","    \"친절\", \"응대\", \"서비스\", \"사장\", \"사장님\", \"직원\", \"알바\",\n","    \"주방\", \"센스\", \"정성\", \"신경\", \"배려\", \"설명\",\n","}\n","\n","AMBIENCE_TERMS = {\n","    \"분위기\", \"인테리어\", \"음악\", \"조명\", \"노래\", \"감성\",\n","    \"깔끔\", \"청결\", \"위생\", \"쾌적\", \"아늑\", \"조용\", \"시끄럽\",\n","    \"자리\", \"좌석\", \"테이블\", \"내부\", \"외부\", \"창문\", \"창가\",\n","}\n","\n","PRICE_TERMS = {\n","    \"가격\", \"가성비\", \"저렴\", \"비싸\", \"합리\", \"혜자\",\n","    \"만원\", \"천원\", \"물가\", \"매우\", \"합리\", \"할인\",\n","}\n","\n","QUANTITY_TERMS = {\n","    \"양도\", \"양이\", \"양은\", \"양\", \"푸짐\", \"넉넉\", \"배부르\",\n","    \"배불리\", \"든든\", \"가득\", \"한입\", \"가득\",\n","}\n","\n","SITUATION_TERMS = {\n","    # 관계/타깃\n","    \"친구\", \"가족\", \"아이\", \"아이들\", \"부모\", \"엄마\", \"아빠\",\n","    \"남편\", \"남자친구\", \"여자친구\", \"연인\", \"부부\", \"직장인\",\n","    \"대학생\", \"학생\", \"혼자\", \"혼밥\", \"커플\",\n","\n","    # 용도/상황\n","    \"데이트\", \"회식\", \"모임\", \"단체\", \"회식\", \"외식\", \"야식\",\n","    \"점심\", \"점심시간\", \"저녁\", \"브런치\", \"주말\", \"방학\",\n","\n","    # 지역/상권\n","    \"인하대\", \"인하대학교\", \"인하대역\", \"용현동\", \"동네\", \"대학가\",\n","    \"인천\", \"송도\", \"서울\", \"본점\", \"골목\",\n","}\n","\n","DOMAIN_KEYWORDS = (\n","    MENU_TERMS | TASTE_TERMS | SERVICE_TERMS |\n","    AMBIENCE_TERMS | PRICE_TERMS | QUANTITY_TERMS | SITUATION_TERMS\n",")\n","DOMAIN_KEYWORDS_LEN3 = {w for w in DOMAIN_KEYWORDS if len(w) >= 3}\n","\n","DOMAIN_STOPWORDS = {\n","    # 강도/상투 부사\n","    \"정말\", \"진짜\", \"너무\", \"너무너무\", \"굉장히\", \"매우\", \"엄청\",\n","    \"엄청나\", \"완전\", \"진심\", \"항상\", \"맨날\", \"매번\", \"종종\",\n","    \"조금\", \"약간\", \"적당히\", \"넘넘\", \"상당히\", \"꽤\",\n","\n","    # 시간/상황 표현 (형식적)\n","    \"오늘\", \"어제\", \"이번\", \"저번\", \"다음\", \"다음번\", \"주말\",\n","    \"요즘\", \"최근\", \"방학\", \"날씨\", \"하루\", \"일주일\",\n","\n","    # 리뷰/행동 표현\n","    \"방문\", \"이용\", \"선택\", \"예약\", \"결제\", \"검색\", \"리뷰\", \"후기\",\n","    \"사용\", \"작성\", \"이렇\", \"이예\", \"라고\", \"해서\", \"벌써\",\n","\n","    # 감정 표현 중 정보량 적은 것\n","    \"행복\", \"행복합니다\", \"감사\", \"감동\", \"재밌\", \"재미\",\n","\n","    # 기타 포괄적인 일반어\n","    \"그냥\", \"솔직히\", \"정도\", \"부분\", \"전체\", \"일단\",\n","}"],"metadata":{"id":"pnUl4Vwn4vA-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# %% 자의적 리뷰 데이터 준비\n","import numpy as np\n","import pandas as pd\n","from collections import Counter\n","\n","def align_kakao_to_naver(\n","    naver_df: pd.DataFrame,\n","    kakao_df: pd.DataFrame,\n","    col_map: dict,\n",") -> pd.DataFrame:\n","    \"\"\"\n","    Kakao 리뷰를 Naver 스키마에 맞게 매핑한 뒤 두 데이터프레임을 수직 결합한다.\n","    - col_map에 정의되지 않은 Kakao 컬럼은 무시\n","    - Naver에 없는 컬럼은 생성하지 않음\n","    \"\"\"\n","    effective_map = {\n","        k: v\n","        for k, v in col_map.items()\n","        if (k in kakao_df.columns) and (v in naver_df.columns)\n","    }\n","\n","    kakao_aligned = kakao_df[list(effective_map.keys())].rename(columns=effective_map)\n","\n","    # Naver에는 있는데 Kakao에는 없는 컬럼은 NaN으로 채움\n","    for col in naver_df.columns:\n","        if col not in kakao_aligned.columns:\n","            kakao_aligned[col] = pd.NA\n","\n","    kakao_aligned = kakao_aligned[naver_df.columns]\n","\n","    merged = pd.concat([naver_df, kakao_aligned], ignore_index=True)\n","    return merged\n","\n","def filter_voluntary_reviews(\n","    df: pd.DataFrame,\n","    text_col: str = \"리뷰내용\",\n","    ad_pred_col: str = \"ad_pred\",   # 0=자의적, 1=광고\n",") -> pd.DataFrame:\n","    \"\"\"\n","    광고성 예측 라벨을 이용해 자의적 리뷰 코퍼스를 구성한다.\n","    - ad_pred == 0인 리뷰만 사용\n","    - 텍스트 길이가 MIN_REVIEW_LENGTH 미만인 리뷰는 제거\n","    \"\"\"\n","    df = df.copy()\n","    df[text_col] = df[text_col].fillna(\"\")\n","\n","    mask = (df[ad_pred_col] == 0) & (df[text_col].str.len() >= MIN_REVIEW_LENGTH)\n","    df = df[mask].reset_index(drop=True)\n","    return df\n","\n","naver_scored = pd.read_csv(SCORED_DIR / \"Naver_Reviews_AdScored.csv\", encoding=\"utf-8-sig\")\n","kakao_scored = pd.read_csv(SCORED_DIR / \"Kakao_Reviews_AdScored.csv\", encoding=\"utf-8-sig\")\n","\n","merged_reviews = align_kakao_to_naver(naver_scored, kakao_scored, KAKAO_TO_NAVER_COLS)\n","print(merged_reviews['ad_pred'].value_counts())\n","reviews_corpus = filter_voluntary_reviews(merged_reviews, text_col=\"리뷰내용\", ad_pred_col=\"ad_pred\")\n","print(\"원본 리뷰 수:\", len(merged_reviews))\n","print(\"자의적 리뷰 수:\", len(reviews_corpus))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o55XUuSUtv3X","executionInfo":{"status":"ok","timestamp":1763392662882,"user_tz":-540,"elapsed":3526,"user":{"displayName":"이상호/학생/경영학","userId":"05009782283079843159"}},"outputId":"b5a9e20c-f9bd-44e6-d9ef-3a3860d2860e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3690851382.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n","  merged = pd.concat([naver_df, kakao_aligned], ignore_index=True)\n"]},{"output_type":"stream","name":"stdout","text":["ad_pred\n","0    22729\n","1     6500\n","Name: count, dtype: int64\n","원본 리뷰 수: 31070\n","자의적 리뷰 수: 13975\n"]}]},{"cell_type":"code","source":["# %% SBERT + BERTopic 토픽 모델링 & 가게별 키워드/바이그램 추출\n","import re\n","import numpy as np\n","import pandas as pd\n","from collections import Counter\n","from sklearn.metrics import silhouette_score\n","from konlpy.tag import Komoran\n","from sentence_transformers import SentenceTransformer\n","from bertopic import BERTopic\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","\n","# ---------------------------------------------------\n","# 공통 유틸\n","# ---------------------------------------------------\n","\n","def clean_text(text: str) -> str:\n","    \"\"\"이모지/제어문자 제거 및 공백 정리.\"\"\"\n","    if not isinstance(text, str):\n","        text = str(text)\n","    text = ALLOWED_PATTERN.sub(\" \", text)\n","    text = re.sub(r\"\\s+\", \" \", text).strip()\n","    return text\n","\n","\n","def is_one_char_diff(a: str, b: str) -> bool:\n","    \"\"\"길이가 같을 때 서로 다른 글자가 정확히 1개면 True.\"\"\"\n","    if len(a) != len(b):\n","        return False\n","    diff = 0\n","    for ca, cb in zip(a, b):\n","        if ca != cb:\n","            diff += 1\n","            if diff > 1:\n","                return False\n","    return diff == 1\n","\n","\n","def correct_with_domain_dict(lemma: str) -> str:\n","    \"\"\"\n","    lemma가 도메인 사전 단어와 한 글자만 다르면\n","    그 도메인 단어로 교정해 반환.\n","    여러 후보가 있으면 그대로 둔다(모호성 회피).\n","    \"\"\"\n","    if len(lemma) < 3:\n","        return lemma\n","\n","    candidates = [\n","        w for w in DOMAIN_KEYWORDS_LEN3\n","        if len(w) == len(lemma) and is_one_char_diff(lemma, w)\n","    ]\n","\n","    if len(candidates) == 1:\n","        return candidates[0]\n","    else:\n","        return lemma\n","\n","def is_valid_bigram(w1: str, w2: str) -> bool:\n","    \"\"\"\n","    DOMAIN_KEYWORDS 구조를 고려해 '말이 되는' 바이그램만 허용.\n","    - 같은 단어 두 번 반복: 금지 (맛있 맛있 등)\n","    - 역할 조합이 의미 있는 경우만 True\n","    \"\"\"\n","    # 1) 동일 단어 반복 금지\n","    if w1 == w2:\n","        return False\n","\n","    # 2) 각 단어의 타입判定\n","    def word_type(w):\n","        if w in MENU_TERMS:\n","            return \"menu\"\n","        if w in TASTE_TERMS:\n","            return \"taste\"\n","        if w in SERVICE_TERMS:\n","            return \"service\"\n","        if w in AMBIENCE_TERMS:\n","            return \"ambience\"\n","        if w in PRICE_TERMS:\n","            return \"price\"\n","        if w in QUANTITY_TERMS:\n","            return \"quantity\"\n","        if w in SITUATION_TERMS:\n","            return \"situation\"\n","        return \"other\"\n","\n","    t1 = word_type(w1)\n","    t2 = word_type(w2)\n","\n","    # 3) 허용할 조합 정의\n","    # 메뉴 + 맛/가격/양\n","    if t1 == \"menu\" and t2 in {\"taste\", \"price\", \"quantity\"}:\n","        return True\n","    # 맛/가격/양 + 메뉴  (국물 떡볶이 이런 건 애매하지만 허용 여부는 선택)\n","    if t1 in {\"taste\", \"price\", \"quantity\"} and t2 == \"menu\":\n","        return True\n","\n","    # 상황 + 메뉴/분위기 (인하대 떡볶이, 데이트 술집 등)\n","    if t1 == \"situation\" and t2 in {\"menu\", \"ambience\"}:\n","        return True\n","\n","    # 기타: 특별히 허용하고 싶은 패턴이 있으면 추가\n","    # 예: '가성비 좋', '분위기 좋' 등 taste형 용언과의 조합\n","    if w2 in {\"좋\", \"괜찮\", \"훌륭\"} and t1 in {\"menu\", \"ambience\", \"price\"}:\n","        return True\n","\n","    return False\n","\n","\n","def tokenize_for_domain(text: str):\n","    \"\"\"\n","    하나의 문장을 도메인 사전/불용어/형태소 필터링을 통과한 토큰 리스트로 변환.\n","    - KEYWORD_POS_TAGS: 사용할 품사 (NNG/NNP/VA/MAG/XR 등)\n","    - DOMAIN_STOPWORDS, VERB_STOP_LEMMAS: 도메인/동사 불용어\n","    - DOMAIN_KEYWORDS: 식당 도메인 핵심 키워드 사전\n","    \"\"\"\n","    text = clean_text(text)\n","    if not text:\n","        return []\n","\n","    try:\n","        morphs = MORPH_ANALYZER.pos(text)\n","    except Exception:\n","        return []\n","\n","    tokens = []\n","    for lemma, pos in morphs:\n","        # 1) 품사 필터\n","        if pos not in KEYWORD_POS_TAGS:\n","            continue\n","\n","        # 2) 숫자 제거\n","        if lemma.isdigit():\n","            continue\n","\n","        # 3) 기호/이모티콘 제거\n","        if not re.search(r\"[가-힣A-Za-z0-9]\", lemma):\n","            continue\n","\n","        # 4) 길이 1 제거\n","        if len(lemma) <= 1:\n","            continue\n","\n","        # 5) 도메인/동사 불용어 제거\n","        if lemma in DOMAIN_STOPWORDS:\n","            continue\n","\n","        # 6) 도메인 사전 기반 오탈자 교정\n","        lemma = correct_with_domain_dict(lemma)\n","\n","        # 7) 도메인 키워드에 없는 단어는 제외\n","        if lemma not in DOMAIN_KEYWORDS:\n","            continue\n","\n","        tokens.append(lemma)\n","\n","    return tokens\n","\n","\n","# ---------------------------------------------------\n","# SBERT + BERTopic (리뷰 수준 토픽)\n","# ---------------------------------------------------\n","\n","def build_review_topics(\n","    df: pd.DataFrame,\n","    text_col: str = \"리뷰내용\",\n","    sbert_model: SentenceTransformer = None,\n","    batch_size: int = 64,\n","):\n","    if sbert_model is None:\n","        sbert_model = SBERT_MODEL\n","\n","    df = df.copy()\n","    df[text_col] = df[text_col].fillna(\"\").apply(clean_text)\n","    docs = df[text_col].tolist()\n","\n","    # 1) SBERT 임베딩\n","    embeddings = sbert_model.encode(\n","        docs,\n","        batch_size=batch_size,\n","        show_progress_bar=True,\n","        convert_to_numpy=True,\n","    )\n","    embeddings = np.nan_to_num(embeddings, nan=0.0, posinf=1e3, neginf=-1e3)\n","\n","    # 2) BERTopic용 CountVectorizer (pruning을 최대한 느슨하게)\n","    vectorizer_model = CountVectorizer(\n","        token_pattern=r\"(?u)\\b[가-힣A-Za-z0-9]+\\b\",\n","        max_df=0.98,      # 아주 자주 나오는 단어 일부만 제거\n","        min_df=1,         # 토픽 문서 수에 상관없이 항상 최소 1개 문서에서만 나와도 허용\n","        ngram_range=(1, 1),   # 우선 1-gram만 사용 (2-gram은 Komoran 바이그램으로 보강)\n","        max_features=20_000,\n","    )\n","\n","    topic_model = BERTopic(\n","        vectorizer_model=vectorizer_model,\n","        calculate_probabilities=True,\n","        verbose=True,\n","    )\n","\n","    topics, probs = topic_model.fit_transform(docs, embeddings)\n","    print(\"고유 토픽 수:\", len(set(topics)))\n","\n","    df_topics = df.copy()\n","    df_topics[\"topic\"] = topics\n","    df_topics[\"topic_prob\"] = probs.max(axis=1)\n","\n","    return df_topics, topic_model, embeddings\n","\n","\n","# ---------------------------------------------------\n","# 전역 바이그램 사전 생성\n","# ---------------------------------------------------\n","\n","def build_global_bigrams(\n","    corpus_df: pd.DataFrame,\n","    text_col: str = \"리뷰내용\",\n","    min_count: int = 20,\n","):\n","    bigram_counter = Counter()\n","\n","    for text in corpus_df[text_col].fillna(\"\"):\n","        tokens = tokenize_for_domain(text)\n","        for i in range(len(tokens) - 1):\n","            w1, w2 = tokens[i], tokens[i+1]\n","            # 말이 되는 바이그램만 카운트\n","            if not is_valid_bigram(w1, w2):\n","                continue\n","            bg = f\"{w1} {w2}\"\n","            bigram_counter[bg] += 1\n","\n","    global_bigrams = {\n","        bg for bg, c in bigram_counter.items() if c >= min_count\n","    }\n","    return global_bigrams\n","\n","\n","# ---------------------------------------------------\n","# 가게별: 3개 대표 바이그램 + 12개 단일 키워드 추출\n","# ---------------------------------------------------\n","\n","def extract_keywords_and_bigrams_for_store(\n","    texts,\n","    global_bigrams,\n","    top_unigrams: int = 12,\n","    top_bigrams: int = 3,\n","):\n","    unigram_counter = Counter()\n","    bigram_counter = Counter()\n","\n","    for text in texts:\n","        tokens = tokenize_for_domain(text)\n","        if not tokens:\n","            continue\n","\n","        for t in tokens:\n","            unigram_counter[t] += 1\n","\n","        for i in range(len(tokens) - 1):\n","            w1, w2 = tokens[i], tokens[i+1]\n","            if not is_valid_bigram(w1, w2):\n","                continue\n","            bg = f\"{w1} {w2}\"\n","            if bg in global_bigrams:\n","                bigram_counter[bg] += 1\n","\n","    top_bigram_list = [bg for bg, _ in bigram_counter.most_common(top_bigrams)]\n","    top_unigram_list = [w for w, _ in unigram_counter.most_common(top_unigrams)]\n","    combined_keywords = top_bigram_list + top_unigram_list\n","    return combined_keywords, top_bigram_list, top_unigram_list\n","\n","\n","def build_store_profiles(\n","    df_topics: pd.DataFrame,\n","    topic_model: BERTopic,\n","    global_bigrams,\n","    store_col: str = \"가게이름\",\n","    text_col: str = \"리뷰내용\",\n",") -> pd.DataFrame:\n","    \"\"\"\n","    리뷰별 topic 정보를 가게 단위로 집계해:\n","    - topic_distribution: {topic_id: 비율}\n","    - keywords: 대표 bigram 3개 + 단일 키워드 12개\n","    - bigrams/unigrams: 필요 시 별도 컬럼으로도 저장\n","    \"\"\"\n","    rows = []\n","\n","    for store, group in df_topics.groupby(store_col):\n","        # 1) 해당 가게의 토픽 분포\n","        topic_counts = group[\"topic\"].value_counts(normalize=True)\n","\n","        # 2) Komoran 기반 토큰에서 바이그램 + 단일 키워드 추출\n","        texts = group[text_col].tolist()\n","        combined_keywords, top_bigrams, top_unigrams = (\n","            extract_keywords_and_bigrams_for_store(\n","                texts,\n","                global_bigrams=global_bigrams,\n","                top_unigrams=12,\n","                top_bigrams=3,\n","            )\n","        )\n","\n","        rows.append(\n","            {\n","                store_col: store,\n","                \"topic_distribution\": topic_counts.to_dict(),\n","                \"keywords\": combined_keywords,   # [3 bigrams + 12 unigrams]\n","                \"bigrams\": top_bigrams,          # 선택: 별도로 보고 싶을 때\n","                \"unigrams\": top_unigrams,        # 선택: 별도로 보고 싶을 때\n","            }\n","        )\n","\n","    store_profiles = pd.DataFrame(rows)\n","    return store_profiles\n","\n","\n","# 전역 바이그램 사전 생성\n","global_bigrams = build_global_bigrams(\n","    corpus_df=reviews_corpus,\n","    text_col=\"리뷰내용\",\n","    min_count=20,   # 코퍼스 크기에 따라 10~30 사이에서 조정\n",")\n","\n","# 리뷰 수준 토픽 모델링\n","review_topics, topic_model, embeddings = build_review_topics(\n","    reviews_corpus,\n","    text_col=\"리뷰내용\",\n",")\n","\n","# 가게별 프로파일 (3개 바이그램 + 12개 단일 키워드)\n","store_profiles = build_store_profiles(\n","    review_topics,\n","    topic_model,\n","    global_bigrams=global_bigrams,\n","    store_col=\"가게이름\",\n","    text_col=\"리뷰내용\",\n",")\n","print(store_profiles.head(15))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["f8d3a971f0304fa1a63d74da48acef74","a325f77a50ba414e878c5cb1bcc38dc0","c4ae49645638432e90eadb8e37448d4a","f89cfd8da98946d58920778f00cbcf65","7e428a98facb4eaeaab1522f59a613e5","72023f3bc5784935a6cd66935b85652c","e1eaed069f154ffe8bb24abbc0954c88","8a85024c98c44a95b0036d12bb09194a","e5f14c20ae5949188ecdf84381de9adc","4d8cd62a0a8c4cde95dae63ecdd9e86e","ec48be5421624816b59ffa26f0385ab5"]},"id":"OtkBFzuNu-JZ","executionInfo":{"status":"ok","timestamp":1763393256407,"user_tz":-540,"elapsed":84526,"user":{"displayName":"이상호/학생/경영학","userId":"05009782283079843159"}},"outputId":"e8531687-bc18-4cb1-a94e-633ffb29aa73"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Batches:   0%|          | 0/219 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8d3a971f0304fa1a63d74da48acef74"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2025-11-17 15:27:14,113 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n","2025-11-17 15:27:14,359 - BERTopic - Dimensionality - Completed ✓\n","2025-11-17 15:27:14,362 - BERTopic - Cluster - Start clustering the reduced embeddings\n","/usr/local/lib/python3.12/dist-packages/hdbscan/prediction.py:663: RuntimeWarning: invalid value encountered in scalar divide\n","  in_cluster_probs = all_points_prob_in_some_cluster(\n","2025-11-17 15:27:16,239 - BERTopic - Cluster - Completed ✓\n","2025-11-17 15:27:16,247 - BERTopic - Representation - Fine-tuning topics using representation models.\n","2025-11-17 15:27:16,341 - BERTopic - Representation - Completed ✓\n"]},{"output_type":"stream","name":"stdout","text":["고유 토픽 수: 19\n","             가게이름                                 topic_distribution  \\\n","0           153횟집    {0: 0.6666666666666666, -1: 0.3333333333333333}   \n","1            29포차    {-1: 0.6842105263157895, 0: 0.3157894736842105}   \n","2      87닭강정 인하대점    {-1: 0.6666666666666666, 0: 0.3333333333333333}   \n","3    BBQ치킨 인하대후문점                                           {0: 1.0}   \n","4     BitterSweet    {-1: 0.7142857142857143, 0: 0.2857142857142857}   \n","5   SHOHONA KEBAB                                           {0: 1.0}   \n","6            UZ케밥                                           {0: 1.0}   \n","7             가메이  {-1: 0.6181818181818182, 0: 0.3454545454545454...   \n","8            가시버시  {-1: 0.46153846153846156, 0: 0.384615384615384...   \n","9      감탄떡볶이 인하대점   {-1: 0.8461538461538461, 0: 0.15384615384615385}   \n","10          경동삼겹살   {-1: 0.6538461538461539, 0: 0.34615384615384615}   \n","11         계속 쪼르면  {-1: 0.6633333333333333, 0: 0.3033333333333333...   \n","12           고양이눈  {-1: 0.6086956521739131, 0: 0.3478260869565217...   \n","13        교반 인하대점  {-1: 0.5679012345679012, 0: 0.3703703703703703...   \n","14   국가대표109 인하대점  {-1: 0.5208333333333334, 0: 0.4375, 2: 0.02083...   \n","\n","                                             keywords  \\\n","0   [초밥 맛있, 맛있 새우, 새우 맛있, 맛있, 초밥, 새우, 사장, 친절, 점심, ...   \n","1   [닭갈비 맛있, 맛있, 친구, 친절, 분위기, 저렴, 테이블, 과일, 사장, 직원,...   \n","2                                  [맛있, 매콤, 양이, 바삭바삭]   \n","3                   [직원, 친절, 인하대, 쾌적, 분위기, 부드럽, 바삭바삭]   \n","4   [새우 맛있, 맛있, 새우, 친구, 인하대, 분위기, 라면, 김치, 맛나, 알바, ...   \n","5                                                [남편]   \n","6                                      [인테리어, 버거, 양도]   \n","7   [연어 맛있, 맛있 연어, 김치 맛있, 맛있, 연어, 새우, 인하대, 덮밥, 우동,...   \n","8   [맛있 김치, 국물 맛있, 김치 맛있, 맛있, 김치, 가격, 진한, 국물, 깔끔, ...   \n","9   [떡볶이 맛있, 맛있 떡볶이, 국물 맛있, 맛있, 떡볶이, 친절, 순대, 깔끔, 맛...   \n","10  [반찬 맛있, 삼겹살 맛있, 맛있 반찬, 반찬, 맛있, 인하대, 사장, 양도, 가격...   \n","11  [쫄면 맛있, 떡볶이 맛있, 맛있 쫄면, 맛있, 쫄면, 떡볶이, 국물, 가격, 양도...   \n","12  [카레 맛있, 고기 양이, 맛있, 카레, 계란, 맛나, 인하대, 양이, 마늘, 케이...   \n","13  [육회 맛있, 맛있 된장찌개, 된장찌개 맛있, 맛있, 친절, 육회, 육전, 양도, ...   \n","14  [고기 맛있, 가격 고기, 고기 신선, 고기, 맛있, 친절, 된장찌개, 인하대, 사...   \n","\n","                      bigrams  \\\n","0       [초밥 맛있, 맛있 새우, 새우 맛있]   \n","1                    [닭갈비 맛있]   \n","2                          []   \n","3                          []   \n","4                     [새우 맛있]   \n","5                          []   \n","6                          []   \n","7       [연어 맛있, 맛있 연어, 김치 맛있]   \n","8       [맛있 김치, 국물 맛있, 김치 맛있]   \n","9     [떡볶이 맛있, 맛있 떡볶이, 국물 맛있]   \n","10     [반찬 맛있, 삼겹살 맛있, 맛있 반찬]   \n","11     [쫄면 맛있, 떡볶이 맛있, 맛있 쫄면]   \n","12             [카레 맛있, 고기 양이]   \n","13  [육회 맛있, 맛있 된장찌개, 된장찌개 맛있]   \n","14      [고기 맛있, 가격 고기, 고기 신선]   \n","\n","                                             unigrams  \n","0   [맛있, 초밥, 새우, 사장, 친절, 점심, 가격, 싱싱, 아이, 국물, 인하대, 소바]  \n","1         [맛있, 친구, 친절, 분위기, 저렴, 테이블, 과일, 사장, 직원, 닭갈비]  \n","2                                  [맛있, 매콤, 양이, 바삭바삭]  \n","3                   [직원, 친절, 인하대, 쾌적, 분위기, 부드럽, 바삭바삭]  \n","4   [맛있, 새우, 친구, 인하대, 분위기, 라면, 김치, 맛나, 알바, 응대, 저렴,...  \n","5                                                [남편]  \n","6                                      [인테리어, 버거, 양도]  \n","7   [맛있, 연어, 새우, 인하대, 덮밥, 우동, 양이, 양도, 가격, 친절, 신선, ...  \n","8   [맛있, 김치, 가격, 진한, 국물, 깔끔, 분위기, 칼국수, 육회, 양도, 친구,...  \n","9   [맛있, 떡볶이, 친절, 순대, 깔끔, 맛나, 국물, 사장, 바삭, 분식, 테이블,...  \n","10  [반찬, 맛있, 인하대, 사장, 양도, 가격, 친절, 삼겹살, 채소, 냉면, 푸짐,...  \n","11  [맛있, 쫄면, 떡볶이, 국물, 가격, 양도, 돈가스, 야채, 맛나, 쫄깃, 친구,...  \n","12  [맛있, 카레, 계란, 맛나, 인하대, 양이, 마늘, 케이크, 사장, 서비스, 돈가...  \n","13  [맛있, 친절, 육회, 육전, 양도, 인하대, 된장찌개, 가격, 직원, 깔끔, 반찬...  \n","14  [고기, 맛있, 친절, 된장찌개, 인하대, 사장, 저렴, 냉면, 혼자, 아이들, 단...  \n"]}]},{"cell_type":"code","source":["# %% 전용 소규모 한국어 사전 제작, 키워드 추출 후 실행\n","def build_raw_vocab(corpus_df, text_col=\"리뷰내용\"):\n","    counter = Counter()\n","    for text in corpus_df[text_col].fillna(\"\"):\n","        for lemma, pos in MORPH_ANALYZER.pos(clean_text(text)):\n","            if pos not in KEYWORD_POS_TAGS:\n","                continue\n","            if len(lemma) <= 1:\n","                continue\n","            if lemma.isdigit():\n","                continue\n","            if not re.search(r\"[가-힣A-Za-z0-9]\", lemma):\n","                continue\n","            counter[lemma] += 1\n","    return counter\n","\n","raw_vocab = build_raw_vocab(reviews_corpus)\n","common_terms = [w for w, c in raw_vocab.most_common(5000)]\n","\n","with open(DATA_ROOT / 'Common_Terms.txt', 'w', encoding='utf-8') as f:\n","    # ' / '로 연결하여 TXT 파일로 쓰기\n","    f.write(' / '.join(common_terms))"],"metadata":{"collapsed":true,"id":"frWYeJIH2bQp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# %% 리뷰 내용 유사성 기반 가게 군집화\n","import re\n","import hdbscan\n","import umap.umap_ as umap\n","import numpy as np\n","import pandas as pd\n","from collections import Counter\n","from konlpy.tag import Komoran\n","from sentence_transformers import SentenceTransformer\n","from bertopic import BERTopic\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","\n","def build_store_embeddings(\n","    review_topics: pd.DataFrame,\n","    embeddings: np.ndarray,\n","    store_col: str = \"가게이름\",\n","):\n","    \"\"\"\n","    리뷰 수준 SBERT 임베딩을 가게 단위로 평균하여 store-level embedding을 만든다.\n","    \"\"\"\n","    review_topics = review_topics.reset_index(drop=True)\n","    assert len(review_topics) == len(embeddings)\n","\n","    store_embeds = {}\n","    for store, group in review_topics.groupby(store_col):\n","        idx = group.index.values\n","        store_vec = embeddings[idx].mean(axis=0)\n","        store_embeds[store] = store_vec\n","\n","    stores = list(store_embeds.keys())\n","    X = np.vstack([store_embeds[s] for s in stores])\n","    store_emb_df = pd.DataFrame(X)\n","    store_emb_df[store_col] = stores\n","\n","    return store_emb_df\n","\n","\n","# %% 5) 클러스터링 & 클러스터 프로파일링\n","def summarize_cluster_keywords(store_clusters, cluster_id, top_k=10):\n","    rows = store_clusters[store_clusters[\"cluster_id\"] == cluster_id]\n","\n","    bigram_counter = Counter()\n","    unigram_counter = Counter()\n","\n","    for _, row in rows.iterrows():\n","        for bg in row[\"bigrams\"]:\n","            bigram_counter[bg] += 1\n","        for ug in row[\"unigrams\"]:\n","            unigram_counter[ug] += 1\n","\n","    top_bigrams = [bg for bg, _ in bigram_counter.most_common(top_k)]\n","    top_unigrams = [ug for ug, _ in unigram_counter.most_common(top_k)]\n","\n","    return top_bigrams, top_unigrams\n","\n","\n","def summarize_cluster_topics(store_clusters, cluster_id):\n","    rows = store_clusters[store_clusters[\"cluster_id\"] == cluster_id]\n","    agg = Counter()\n","    for dist in rows[\"topic_distribution\"]:\n","        for t, p in dist.items():\n","            agg[t] += p\n","    total = sum(agg.values())\n","    if total > 0:\n","        for t in agg:\n","            agg[t] /= total\n","    return dict(agg)\n","\n","\n","# %% 전체 실행 파이프라인\n","store_profiles[\"n_bigrams\"] = store_profiles[\"bigrams\"].apply(len)\n","store_profiles[\"n_unigrams\"] = store_profiles[\"unigrams\"].apply(len)\n","cluster_candidates = store_profiles[\n","    (store_profiles[\"n_bigrams\"] >= 2) &\n","    (store_profiles[\"n_unigrams\"] >= 5)\n","].copy()\n","\n","# 가게 단위 SBERT 임베딩\n","store_emb_df = build_store_embeddings(\n","    review_topics,\n","    embeddings,\n","    store_col=\"가게이름\",\n",")\n","\n","X_store = store_emb_df.merge(\n","    cluster_candidates[[\"가게이름\"]],\n","    on=\"가게이름\",\n","    how=\"inner\"\n",")\n","store_names = X_store[\"가게이름\"].tolist()\n","X_vec = X_store.drop(columns=[\"가게이름\"]).to_numpy()\n","\n","umap_model = umap.UMAP(\n","        n_neighbors=15,        # 지역 구조 강조 (10~50 범위에서 튜닝)\n","        n_components=15,\n","        min_dist=0.0,          # 클러스터링에 적합하게 점들을 더 조밀하게 배치\n","        metric=\"cosine\",       # SBERT 임베딩에는 cosine이 일반적\n","        random_state=42,\n","    )\n","X_umap = umap_model.fit_transform(X_vec)   # shape: [n_candidates, 15]\n","\n","# 8) HDBSCAN 군집화\n","clusterer = hdbscan.HDBSCAN(\n","    min_cluster_size=5,          # 최소 클러스터 크기 (데이터 보고 5~20 사이 튜닝)\n","    min_samples=2,               # 노이즈 비율 줄이고 싶으면 1~5 정도로 낮춰보기\n","    metric=\"euclidean\",          # UMAP 출력에는 euclidean이 기본\n","    cluster_selection_method=\"eom\",\n",")\n","cluster_labels = clusterer.fit_predict(X_umap)\n","\n","# HDBSCAN 결과: cluster_labels, UMAP 결과: X_umap 라고 가정\n","labels = cluster_labels\n","\n","# 1) 노이즈(-1) 제외한 포인트만 사용\n","mask = labels != -1\n","X_umap_valid = X_umap[mask]\n","labels_valid = labels[mask]\n","\n","n_clusters_valid = len(set(labels_valid))\n","n_points_valid = len(labels_valid)\n","\n","print(\"유효 포인트 수(노이즈 제외):\", n_points_valid)\n","print(\"유효 클러스터 수(노이즈 제외):\", n_clusters_valid)\n","\n","sil_score = None\n","if n_clusters_valid >= 2 and n_points_valid >= 10:\n","    sil_score = silhouette_score(X_umap_valid, labels_valid, metric=\"euclidean\")\n","    print(\"실루엣 스코어 (UMAP 공간, 노이즈 제외):\", sil_score)\n","else:\n","    print(\"클러스터가 2개 미만이거나 포인트 수가 너무 적어 실루엣 스코어를 계산하지 않습니다.\")\n","\n","# 9) 결과 결합\n","cluster_result = pd.DataFrame(\n","    {\"가게이름\": store_names, \"cluster_id\": cluster_labels}\n",")\n","\n","store_clusters = cluster_result.merge(\n","    store_profiles[[\"가게이름\", \"bigrams\", \"unigrams\", \"topic_distribution\"]],\n","    on=\"가게이름\",\n","    how=\"left\"\n",")\n","\n","print(store_clusters.head())\n","print(store_clusters['cluster_id'].value_counts())"],"metadata":{"id":"-J8Q4fz5CJqt","executionInfo":{"status":"ok","timestamp":1763393359065,"user_tz":-540,"elapsed":498,"user":{"displayName":"이상호/학생/경영학","userId":"05009782283079843159"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8292ce68-0a02-4aad-89be-eabf958daef5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["유효 포인트 수(노이즈 제외): 126\n","유효 클러스터 수(노이즈 제외): 12\n","실루엣 스코어 (UMAP 공간, 노이즈 제외): 0.5334932\n","         가게이름  cluster_id                  bigrams  \\\n","0       153횟집           1    [초밥 맛있, 맛있 새우, 새우 맛있]   \n","1         가메이           3    [연어 맛있, 맛있 연어, 김치 맛있]   \n","2        가시버시           7    [맛있 김치, 국물 맛있, 김치 맛있]   \n","3  감탄떡볶이 인하대점           4  [떡볶이 맛있, 맛있 떡볶이, 국물 맛있]   \n","4       경동삼겹살          -1   [반찬 맛있, 삼겹살 맛있, 맛있 반찬]   \n","\n","                                            unigrams  \\\n","0  [맛있, 초밥, 새우, 사장, 친절, 점심, 가격, 싱싱, 아이, 국물, 인하대, 소바]   \n","1  [맛있, 연어, 새우, 인하대, 덮밥, 우동, 양이, 양도, 가격, 친절, 신선, ...   \n","2  [맛있, 김치, 가격, 진한, 국물, 깔끔, 분위기, 칼국수, 육회, 양도, 친구,...   \n","3  [맛있, 떡볶이, 친절, 순대, 깔끔, 맛나, 국물, 사장, 바삭, 분식, 테이블,...   \n","4  [반찬, 맛있, 인하대, 사장, 양도, 가격, 친절, 삼겹살, 채소, 냉면, 푸짐,...   \n","\n","                                  topic_distribution  \n","0    {0: 0.6666666666666666, -1: 0.3333333333333333}  \n","1  {-1: 0.6181818181818182, 0: 0.3454545454545454...  \n","2  {-1: 0.46153846153846156, 0: 0.384615384615384...  \n","3   {-1: 0.8461538461538461, 0: 0.15384615384615385}  \n","4   {-1: 0.6538461538461539, 0: 0.34615384615384615}  \n","cluster_id\n"," 0     27\n","-1     24\n"," 9     17\n"," 3     14\n"," 8     12\n"," 1      9\n"," 10     8\n"," 5      8\n"," 6      8\n"," 7      7\n"," 4      6\n"," 2      5\n"," 11     5\n","Name: count, dtype: int64\n"]}]},{"cell_type":"code","source":["# %% 가게 군집별 키워드/바이그램 추출\n","from collections import Counter\n","\n","def extract_keywords_and_bigrams_for_cluster(\n","    texts,\n","    global_bigrams,\n","    n_top_unigrams: int = 12,\n","    n_top_bigrams: int = 3,\n","):\n","    unigram_counter = Counter()\n","    bigram_counter = Counter()\n","\n","    for text in texts:\n","        tokens = tokenize_for_domain(text)\n","        if not tokens:\n","            continue\n","\n","        for t in tokens:\n","            unigram_counter[t] += 1\n","\n","        for i in range(len(tokens) - 1):\n","            w1, w2 = tokens[i], tokens[i+1]\n","            if not is_valid_bigram(w1, w2):\n","                continue\n","            bg = f\"{w1} {w2}\"\n","            if bg in global_bigrams:\n","                bigram_counter[bg] += 1\n","\n","    # 방어: n_top_*가 리스트 등으로 잘못 들어오면 길이로 변환\n","    if not isinstance(n_top_bigrams, int):\n","        n_top_bigrams = int(len(n_top_bigrams))\n","    if not isinstance(n_top_unigrams, int):\n","        n_top_unigrams = int(len(n_top_unigrams))\n","\n","    top_bigram_list = [bg for bg, _ in bigram_counter.most_common(n_top_bigrams)]\n","    top_unigram_list = [w for w, _ in unigram_counter.most_common(n_top_unigrams)]\n","    combined_keywords = top_bigram_list + top_unigram_list\n","\n","    return combined_keywords, top_bigram_list, top_unigram_list\n","\n","def build_cluster_profiles(\n","    store_clusters: pd.DataFrame,\n","    reviews_corpus: pd.DataFrame,\n","    global_bigrams,\n","    cluster_col: str = \"cluster_id\",\n","    store_col: str = \"가게이름\",\n","    text_col: str = \"리뷰내용\",\n","    top_unigrams: int = 12,\n","    top_bigrams: int = 3,\n",") -> pd.DataFrame:\n","    reviews_with_cluster = reviews_corpus[[store_col, text_col]].merge(\n","        store_clusters[[store_col, cluster_col]],\n","        on=store_col,\n","        how=\"inner\",\n","    )\n","\n","    reviews_with_cluster = reviews_with_cluster[\n","        reviews_with_cluster[cluster_col] != -1\n","    ].copy()\n","\n","    rows = []\n","\n","    for cluster_id, group in reviews_with_cluster.groupby(cluster_col):\n","        texts = group[text_col].fillna(\"\").tolist()\n","        n_reviews = len(texts)\n","\n","        member_stores = sorted(group[store_col].unique().tolist())\n","        n_stores = len(member_stores)\n","\n","        # 함수 인자는 n_top_* 이름으로 넘긴다\n","        cluster_keywords, cluster_bigrams, cluster_unigrams = (\n","            extract_keywords_and_bigrams_for_cluster(\n","                texts,\n","                global_bigrams=global_bigrams,\n","                n_top_unigrams=top_unigrams,\n","                n_top_bigrams=top_bigrams,\n","            )\n","        )\n","\n","        rows.append(\n","            {\n","                \"cluster_id\": cluster_id,\n","                \"cluster_keywords\": cluster_keywords,\n","                \"cluster_bigrams\": cluster_bigrams,\n","                \"cluster_unigrams\": cluster_unigrams,\n","                \"member_stores\": member_stores,\n","                \"n_stores\": n_stores,\n","                \"n_reviews\": n_reviews,\n","            }\n","        )\n","\n","    cluster_profiles = pd.DataFrame(rows)\n","    return cluster_profiles\n","\n","cluster_profiles = build_cluster_profiles(\n","    store_clusters=store_clusters,\n","    reviews_corpus=reviews_corpus,\n","    global_bigrams=global_bigrams,\n","    cluster_col=\"cluster_id\",\n","    store_col=\"가게이름\",\n","    text_col=\"리뷰내용\",\n","    top_unigrams=12,\n","    top_bigrams=3,\n",")\n","print(cluster_profiles.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gc48k2rEU_ri","executionInfo":{"status":"ok","timestamp":1763393398048,"user_tz":-540,"elapsed":16918,"user":{"displayName":"이상호/학생/경영학","userId":"05009782283079843159"}},"outputId":"00f918d1-1704-4fe7-ad21-792c9de8f84d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["   cluster_id                                   cluster_keywords  \\\n","0           0  [쌀국수 맛있, 전골 맛있, 맛있 쌀국수, 맛있, 분위기, 인하대, 친절, 사장, ...   \n","1           1  [샌드위치 맛있, 샐러드 맛있, 초밥 맛있, 맛있, 친절, 신선, 사장, 샌드위치,...   \n","2           2  [곱창 맛있, 맛있 곱창, 인하대 곱창, 맛있, 곱창, 인하대, 친절, 사장, 김치...   \n","3           3  [라멘 맛있, 국물 맛있, 인하대 라멘, 맛있, 친절, 라멘, 인하대, 사장, 국물...   \n","4           4  [떡볶이 맛있, 쫄면 맛있, 맛있 떡볶이, 맛있, 떡볶이, 쫄면, 친절, 가격, 국...   \n","\n","            cluster_bigrams  \\\n","0   [쌀국수 맛있, 전골 맛있, 맛있 쌀국수]   \n","1  [샌드위치 맛있, 샐러드 맛있, 초밥 맛있]   \n","2    [곱창 맛있, 맛있 곱창, 인하대 곱창]   \n","3    [라멘 맛있, 국물 맛있, 인하대 라멘]   \n","4   [떡볶이 맛있, 쫄면 맛있, 맛있 떡볶이]   \n","\n","                                    cluster_unigrams  \\\n","0  [맛있, 분위기, 인하대, 친절, 사장, 쌀국수, 친구, 양도, 전골, 직원, 가격...   \n","1  [맛있, 친절, 신선, 사장, 샌드위치, 샐러드, 깔끔, 양도, 인하대, 초밥, 가...   \n","2  [맛있, 곱창, 인하대, 친절, 사장, 김치, 국수, 돼지, 양도, 가격, 쫄깃, ...   \n","3  [맛있, 친절, 라멘, 인하대, 사장, 국물, 깔끔, 고기, 신선, 양도, 직원, 가격]   \n","4  [맛있, 떡볶이, 쫄면, 친절, 가격, 국물, 양도, 인하대, 맛나, 사장, 저렴,...   \n","\n","                                       member_stores  n_stores  n_reviews  \n","0  [국민정서 인하대후문점, 국제식당 인하대본점, 당나발포차 인하대점, 도시톡, 디탕 ...        27       2632  \n","1  [153횟집, 덮수룩, 뭉클로 샌드위치 디저트, 샐러리아 인하대점, 스톡홀름 샐러드...         9       1089  \n","2  [미로곱창 전골집, 미로곱창볶음집 인하대점, 스며듦 튀김수육, 연곱, 정인곱창 인하본점]         5        421  \n","3  [가메이, 고양이눈, 금산양꼬치 본점, 라향각마라탕 인하대점, 멘야토리 라멘, 미연...        14       1144  \n","4  [감탄떡볶이 인하대점, 계속 쪼르면, 동대문엽기떡볶이 인천인하대점, 별난만두, 이모...         6        584  \n"]}]},{"cell_type":"code","source":["cluster_profiles"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":147},"id":"SKU2-7JIDplw","executionInfo":{"status":"error","timestamp":1763554812522,"user_tz":-540,"elapsed":8,"user":{"displayName":"이상호","userId":"07129413416403769389"}},"outputId":"753bfeb0-dda5-40a7-818b-07a21430cc56"},"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'cluster_profiles' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2876788562.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcluster_profiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'cluster_profiles' is not defined"]}]},{"cell_type":"code","source":["# %% 군집화 추천 대상 가게\n","import pandas as pd\n","import json\n","\n","store_col = \"가게이름\"\n","\n","# 1) 클러스터가 할당된 가게만 남기기 (cluster_id != -1)\n","clustered_stores = store_clusters[store_clusters[\"cluster_id\"] != -1].copy()\n","\n","# 2) 가게별 키워드 + cluster_id 머지\n","store_profile_clustered = store_profiles.merge(\n","    clustered_stores[[store_col, \"cluster_id\"]],\n","    on=store_col,\n","    how=\"inner\"        # 클러스터 없는 가게 자동 제거\n",")\n","\n","# 3) 군집별 키워드(cluster_bigrams / cluster_unigrams) 머지\n","store_profile_clustered = store_profile_clustered.merge(\n","    cluster_profiles[[\"cluster_id\", \"cluster_bigrams\", \"cluster_unigrams\"]],\n","    on=\"cluster_id\",\n","    how=\"left\"\n",")\n","\n","# 4) 리스트 컬럼을 CSV에 쓰기 좋게 문자열로 변환 (JSON 형식 예시)\n","list_cols = [\"bigrams\", \"unigrams\", \"cluster_bigrams\", \"cluster_unigrams\"]\n","\n","for col in list_cols:\n","    store_profile_clustered[col] = store_profile_clustered[col].apply(\n","        lambda x: json.dumps(x, ensure_ascii=False) if isinstance(x, (list, tuple)) else x\n","    )\n","\n","# 네이버 리뷰에 붙이기\n","naver_with_features = naver_scored.merge(\n","    store_profile_clustered[\n","        [store_col, \"bigrams\", \"unigrams\", \"cluster_id\", \"cluster_bigrams\", \"cluster_unigrams\"]\n","    ],\n","    on=store_col,\n","    how=\"inner\"   # 클러스터 없는 가게 리뷰는 제거\n",")\n","\n","# 카카오 리뷰에 붙이기\n","kakao_with_features = kakao_scored.merge(\n","    store_profile_clustered[\n","        [store_col, \"bigrams\", \"unigrams\", \"cluster_id\", \"cluster_bigrams\", \"cluster_unigrams\"]\n","    ],\n","    on=store_col,\n","    how=\"inner\"\n",")\n","\n","naver_reviews_final = naver_with_features.rename(columns={\n","    \"bigrams\": \"store_bigrams\",\n","    \"unigrams\": \"store_unigrams\",\n","    \"cluster_bigrams\": \"group_bigrams\",\n","    \"cluster_unigrams\": \"group_unigrams\",\n","})\n","print(naver_reviews_final.head())\n","kakao_reviews_final = kakao_with_features.rename(columns={\n","    \"bigrams\": \"store_bigrams\",\n","    \"unigrams\": \"store_unigrams\",\n","    \"cluster_bigrams\": \"group_bigrams\",\n","    \"cluster_unigrams\": \"group_unigrams\",\n","})\n","print(kakao_reviews_final.head())\n","naver_reviews_final.to_csv(DATA_ROOT / \"Naver_Reviews_Final.csv\", index=False)\n","kakao_reviews_final.to_csv(DATA_ROOT / \"Kakao_Reviews_Final.csv\", index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j4w8FDqQWJT2","executionInfo":{"status":"ok","timestamp":1763393418469,"user_tz":-540,"elapsed":769,"user":{"displayName":"이상호/학생/경영학","userId":"05009782283079843159"}},"outputId":"7b3dead4-c5bb-4316-c5d5-a015e86740e2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["                                              도입_URL         가게이름    카테고리  \\\n","0  https://map.naver.com/p/entry/place/1392141383...  효자동솥뚜껑 인하대점  돼지고기구이   \n","1  https://map.naver.com/p/entry/place/1392141383...  효자동솥뚜껑 인하대점  돼지고기구이   \n","2  https://map.naver.com/p/entry/place/1392141383...  효자동솥뚜껑 인하대점  돼지고기구이   \n","3  https://map.naver.com/p/entry/place/1392141383...  효자동솥뚜껑 인하대점  돼지고기구이   \n","4  https://map.naver.com/p/entry/place/1392141383...  효자동솥뚜껑 인하대점  돼지고기구이   \n","\n","  전체평점  방문자리뷰         리뷰작성자  리뷰작성수  \\\n","0  미공개  608.0       Thumbee   14.0   \n","1  미공개  608.0       ysa****   18.0   \n","2  미공개  608.0  yoonyoon1682   32.0   \n","3  미공개  608.0      Bj990803    7.0   \n","4  미공개  608.0          곰탱탱스   47.0   \n","\n","                                                리뷰내용        방문시간  \\\n","0  항강 지나다니던 인하대 골목에서 여러번 지나치다가\\n드디어 오게됫어요!\\n고기들이 ...  2025-10-31   \n","1  😋🔥 효자동 솥뚜껑삼겹살 한판 먹고 왔습니다!\\n두툼한 삼겹살에 김치, 숙주, 버섯...  2025-10-26   \n","2  생긴지 얼마 안된 곳인가?싶게 매장이 깨끗해요(화장실도)\\n직원분들이 진짜 진짜 친...  2025-10-25   \n","3  고기도 부드럽고 반찬도 깔끔해서 너무 잘 먹었어요!\\n직원분들이 친절해서 기분까지 ...  2025-10-18   \n","4  인하대 후문 솥뚜겅삼겹살 다녀왔어!\\n일단 사장님이 너무 친절해서 기분 좋게 먹을 ...  2025-09-16   \n","\n","   X3_Sentiment  ...  label  is_StrongLabeled  validated_label   ad_prob  \\\n","0      0.509985  ...   -1.0             False              NaN  0.128537   \n","1      0.506568  ...   -1.0             False              NaN  0.107492   \n","2      0.505671  ...   -1.0             False              NaN  0.125037   \n","3      0.503141  ...   -1.0             False              NaN  0.132792   \n","4      0.526811  ...   -1.0             False              NaN  0.129110   \n","\n","   ad_pred                  store_bigrams  \\\n","0        0  [\"고기 맛있\", \"맛있 계란찜\", \"인하대 고기\"]   \n","1        0  [\"고기 맛있\", \"맛있 계란찜\", \"인하대 고기\"]   \n","2        0  [\"고기 맛있\", \"맛있 계란찜\", \"인하대 고기\"]   \n","3        0  [\"고기 맛있\", \"맛있 계란찜\", \"인하대 고기\"]   \n","4        0  [\"고기 맛있\", \"맛있 계란찜\", \"인하대 고기\"]   \n","\n","                                      store_unigrams  cluster_id  \\\n","0  [\"맛있\", \"고기\", \"친절\", \"계란찜\", \"인하대\", \"삼겹살\", \"직원\", ...           8   \n","1  [\"맛있\", \"고기\", \"친절\", \"계란찜\", \"인하대\", \"삼겹살\", \"직원\", ...           8   \n","2  [\"맛있\", \"고기\", \"친절\", \"계란찜\", \"인하대\", \"삼겹살\", \"직원\", ...           8   \n","3  [\"맛있\", \"고기\", \"친절\", \"계란찜\", \"인하대\", \"삼겹살\", \"직원\", ...           8   \n","4  [\"맛있\", \"고기\", \"친절\", \"계란찜\", \"인하대\", \"삼겹살\", \"직원\", ...           8   \n","\n","                  group_bigrams  \\\n","0  [\"고기 맛있\", \"맛있 고기\", \"인하대 고기\"]   \n","1  [\"고기 맛있\", \"맛있 고기\", \"인하대 고기\"]   \n","2  [\"고기 맛있\", \"맛있 고기\", \"인하대 고기\"]   \n","3  [\"고기 맛있\", \"맛있 고기\", \"인하대 고기\"]   \n","4  [\"고기 맛있\", \"맛있 고기\", \"인하대 고기\"]   \n","\n","                                      group_unigrams  \n","0  [\"맛있\", \"고기\", \"친절\", \"사장\", \"인하대\", \"가격\", \"삼겹살\", \"...  \n","1  [\"맛있\", \"고기\", \"친절\", \"사장\", \"인하대\", \"가격\", \"삼겹살\", \"...  \n","2  [\"맛있\", \"고기\", \"친절\", \"사장\", \"인하대\", \"가격\", \"삼겹살\", \"...  \n","3  [\"맛있\", \"고기\", \"친절\", \"사장\", \"인하대\", \"가격\", \"삼겹살\", \"...  \n","4  [\"맛있\", \"고기\", \"친절\", \"사장\", \"인하대\", \"가격\", \"삼겹살\", \"...  \n","\n","[5 rows x 31 columns]\n","          가게이름  카테고리  전체평점  평점건수  리뷰수   리뷰작성자       리뷰작성일  작성자리뷰작성수  작성자평균평점  \\\n","0        세구네술집    술집   5.0     1    0      유민  2024-02-14       1.0      5.0   \n","1  라향각마라탕 인하대점  중국요리   4.3     6    0     양고기  2023-04-07       5.0      4.4   \n","2  라향각마라탕 인하대점  중국요리   4.3     6    0     ???  2022-06-09       6.0      4.3   \n","3  라향각마라탕 인하대점  중국요리   4.3     6    0     ams  2021-06-28      53.0      4.9   \n","4  라향각마라탕 인하대점  중국요리   4.3     6    0  맛집 감별사  2020-04-25      50.0      4.2   \n","\n","   리뷰평점  ... label  is_StrongLabeled  validated_label   ad_prob  ad_pred  \\\n","0   5.0  ...  -1.0             False              NaN  0.111292        0   \n","1   5.0  ...  -1.0             False              NaN  0.094520        0   \n","2   4.0  ...  -1.0             False              NaN  0.451054        1   \n","3   5.0  ...  -1.0             False              NaN  0.084122        0   \n","4   5.0  ...  -1.0             False              NaN  0.084091        0   \n","\n","                 store_bigrams  \\\n","0          [\"맛있 삼겹살\", \"갈비 맛있\"]   \n","1  [\"고기 양이\", \"맛있 국물\", \"맛있 고기\"]   \n","2  [\"고기 양이\", \"맛있 국물\", \"맛있 고기\"]   \n","3  [\"고기 양이\", \"맛있 국물\", \"맛있 고기\"]   \n","4  [\"고기 양이\", \"맛있 국물\", \"맛있 고기\"]   \n","\n","                                      store_unigrams  cluster_id  \\\n","0  [\"맛있\", \"사장\", \"분위기\", \"친절\", \"양이\", \"양도\", \"김치찌개\", ...           0   \n","1  [\"맛있\", \"인하대\", \"친절\", \"국물\", \"테이블\", \"고기\", \"양이\", \"...           3   \n","2  [\"맛있\", \"인하대\", \"친절\", \"국물\", \"테이블\", \"고기\", \"양이\", \"...           3   \n","3  [\"맛있\", \"인하대\", \"친절\", \"국물\", \"테이블\", \"고기\", \"양이\", \"...           3   \n","4  [\"맛있\", \"인하대\", \"친절\", \"국물\", \"테이블\", \"고기\", \"양이\", \"...           3   \n","\n","                   group_bigrams  \\\n","0  [\"쌀국수 맛있\", \"전골 맛있\", \"맛있 쌀국수\"]   \n","1   [\"라멘 맛있\", \"국물 맛있\", \"인하대 라멘\"]   \n","2   [\"라멘 맛있\", \"국물 맛있\", \"인하대 라멘\"]   \n","3   [\"라멘 맛있\", \"국물 맛있\", \"인하대 라멘\"]   \n","4   [\"라멘 맛있\", \"국물 맛있\", \"인하대 라멘\"]   \n","\n","                                      group_unigrams  \n","0  [\"맛있\", \"분위기\", \"인하대\", \"친절\", \"사장\", \"쌀국수\", \"친구\", ...  \n","1  [\"맛있\", \"친절\", \"라멘\", \"인하대\", \"사장\", \"국물\", \"깔끔\", \"고...  \n","2  [\"맛있\", \"친절\", \"라멘\", \"인하대\", \"사장\", \"국물\", \"깔끔\", \"고...  \n","3  [\"맛있\", \"친절\", \"라멘\", \"인하대\", \"사장\", \"국물\", \"깔끔\", \"고...  \n","4  [\"맛있\", \"친절\", \"라멘\", \"인하대\", \"사장\", \"국물\", \"깔끔\", \"고...  \n","\n","[5 rows x 33 columns]\n"]}]}]}